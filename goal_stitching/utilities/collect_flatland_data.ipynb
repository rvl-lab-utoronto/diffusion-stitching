{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file generates the data used in the Flatland+ experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports, parameters, etc. \n",
    "from flatland_plus_environment import FlatLandPlus\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "MAX_EP_LENGTH = 200\n",
    "TOTAL_SAMPLES = 100_000 # OGBench had 1 million but this seems more reasonable for this\n",
    "HOLDOUT_SPLIT = 0.3333\n",
    "RANDOM_SEED = 42\n",
    "save_directory = 'flatland_data'\n",
    "N_list = [2]\n",
    "SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 2)\n"
     ]
    }
   ],
   "source": [
    "from flatland_plus_environment import FlatLandPlus\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "for N in N_list:\n",
    "    # Collects and shuffles all possible Start-Goal pairs, sorts into \n",
    "    # training and testing\n",
    "    sg_pairs = []\n",
    "    n_facets = N * 2 \n",
    "    for start_index in range(n_facets):\n",
    "        for goal_index in range(n_facets):\n",
    "            if start_index != goal_index:\n",
    "                sg_pairs.append(tuple((start_index,goal_index)))\n",
    "    rng = np.random.default_rng(seed=RANDOM_SEED)\n",
    "    rng.shuffle(sg_pairs)\n",
    "    training_split = sg_pairs[:1-int(HOLDOUT_SPLIT*len(sg_pairs))]\n",
    "    testing_split = sg_pairs[1-int(HOLDOUT_SPLIT*len(sg_pairs)):]\n",
    "    assert len(sg_pairs) == len(training_split) + len(testing_split)\n",
    "    #print('train',training_split)\n",
    "    #print('test',testing_split)\n",
    "    # some setup stuff\n",
    "    timeout = MAX_EP_LENGTH\n",
    "    env = FlatLandPlus(n_dims = N)\n",
    "    n_sg_pairs = int(n_facets * (n_facets-1))\n",
    "    rng = np.random.default_rng(seed = 42)\n",
    "    gaussian_scale = 0.05\n",
    "    obs_record = []\n",
    "    actions = []\n",
    "    terminals = []\n",
    "    sg_index = 0\n",
    "    for rollout in range(int(TOTAL_SAMPLES/MAX_EP_LENGTH)):\n",
    "        # setup\n",
    "        (start_index, goal_index) = training_split[sg_index]\n",
    "        been_to_middle = False\n",
    "        obs, info = env.reset(start_idx=start_index,goal_idx=goal_index)\n",
    "        start = obs\n",
    "        goal = info['goal']\n",
    "        middle = np.zeros_like(start)\n",
    "        truncated = False\n",
    "        # overall environment interaction loop\n",
    "        while not truncated:\n",
    "            obs_record.append(obs)\n",
    "            if not been_to_middle: # travelling from start to middle\n",
    "                # base action going towards middle\n",
    "                action = middle-obs\n",
    "                # adds small gaussian noise \n",
    "                action = action + rng.normal(loc=0,scale=gaussian_scale,size=action.shape)\n",
    "            else: # travelling from middle to goal\n",
    "                # base action going towards goal\n",
    "                action = goal-obs\n",
    "                # adds small gaussian noise \n",
    "                action = action + rng.normal(loc=0,scale=gaussian_scale,size=action.shape)\n",
    "            # executes action\n",
    "            obs, _ , _, truncated, _ = env.step(action)\n",
    "            if np.linalg.norm(obs) < env.tolerance:\n",
    "                been_to_middle = True\n",
    "            actions.append(action)\n",
    "            terminals.append(truncated)\n",
    "        # sg index handling\n",
    "        sg_index +=1\n",
    "        if sg_index >= len(training_split):\n",
    "            sg_index = 0\n",
    "    obs_record, actions, terminals = np.array(obs_record), np.array(actions), np.array(terminals)\n",
    "    print(obs_record.shape)\n",
    "    save_dict = {'observations':obs_record,'terminals':terminals,'actions':actions}\n",
    "    np.save(save_directory+'/dataset_n'+str(N) +'.npy',save_dict)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [(0, 1), (2, 1), (2, 0), (3, 0), (3, 2), (1, 0), (1, 3), (0, 3), (1, 2), (3, 1)]\n",
      "test [(0, 2), (2, 3)]\n"
     ]
    }
   ],
   "source": [
    "# this cell just prints the train/test splits for each so you\n",
    "# can easily grab some of the testing splits for a given dataset\n",
    "for N in N_list:\n",
    "    # Collects and shuffles all possible Start-Goal pairs, sorts into \n",
    "    # training and testing\n",
    "    sg_pairs = []\n",
    "    n_facets = N * 2 \n",
    "    for start_index in range(n_facets):\n",
    "        for goal_index in range(n_facets):\n",
    "            if start_index != goal_index:\n",
    "                sg_pairs.append(tuple((start_index,goal_index)))\n",
    "    rng = np.random.default_rng(seed=RANDOM_SEED)\n",
    "    rng.shuffle(sg_pairs)\n",
    "    training_split = sg_pairs[:1-int(HOLDOUT_SPLIT*len(sg_pairs))]\n",
    "    testing_split = sg_pairs[1-int(HOLDOUT_SPLIT*len(sg_pairs)):]\n",
    "    assert len(sg_pairs) == len(training_split) + len(testing_split)\n",
    "    print('train',training_split)\n",
    "    print('test',testing_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
